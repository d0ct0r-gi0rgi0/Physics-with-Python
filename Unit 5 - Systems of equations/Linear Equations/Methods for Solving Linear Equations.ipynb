{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc27be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4f4f21",
   "metadata": {},
   "source": [
    "# Methods for Solving Linear Equations.\n",
    "\n",
    "- We want to solve numerically a system of $n$ linear equations with $n$ unknowns of the form:\n",
    "\n",
    "    \\begin{align}\n",
    "    a_{11}\\,x_1+a_{12}\\,x_2+\\cdots+a_{1n}\\,x_n &= b_1,\\nonumber\\\\\n",
    "    a_{21}\\,x_1+a_{22}\\,x_2+\\cdots+a_{2n}\\,x_n &= b_2,\\nonumber\\\\\n",
    "    \\vdots\\quad\\qquad\\vdots\\qquad\\qquad\\vdots\\quad&\\quad\\vdots\\nonumber\\\\\n",
    "    a_{n1}\\,x_1+a_{n2}\\,x_2+\\cdots+a_{nn}\\,x_n &=b_n,\\nonumber\\\\\n",
    "    \\end{align}\n",
    "\n",
    "    or in matrix formulation:\n",
    "\n",
    "    $$A\\cdot X =B,$$\n",
    "\n",
    "    with\n",
    "\n",
    "$$A=\\left(\n",
    "\\begin{array}{cccc}\n",
    "a_{11}&a_{12}&\\cdots&a_{1n}\\nonumber\\\\\n",
    "a_{21}&a_{22}&\\cdots&a_{2n}\\nonumber\\\\\n",
    "\\vdots&\\vdots&\\ddots&\\vdots\\nonumber\\\\\n",
    "a_{n1}&a_{n2}&\\cdots&a_{nn}\\nonumber\\\\\n",
    "\\end{array}\\right),\\quad\n",
    "X=\\left(\n",
    "\\begin{array}{c}\n",
    "x_1\\nonumber\\\\\n",
    "x_2\\nonumber\\\\\n",
    "\\vdots\\nonumber\\\\\n",
    "x_n\\nonumber\\\\\n",
    "\\end{array}\n",
    "\\right)\\quad\\text{and}\\quad B=\\left(\n",
    "\\begin{array}{c}\n",
    "b_1\\nonumber\\\\\n",
    "b_2\\nonumber\\\\\n",
    "\\vdots\\nonumber\\\\\n",
    "b_n\\nonumber\\\\\n",
    "\\end{array}\n",
    "\\right).\n",
    "$$\n",
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Gaussian Elimination.\n",
    "\n",
    "- The idea of the method is to use elementary matrix operations that allow us to transform our initial system of equations into one in which the matrix $A$ is triangular.\n",
    "\n",
    "- To do this, we first construct the augmented matrix:\n",
    "\n",
    "$$\\left(A\\vert B\\right)=\\left(\n",
    "\\begin{array}{cccccc}\n",
    "a_{11}&a_{12}&\\cdots&a_{1n}&\\vert& b_1\\nonumber\\\\\n",
    "a_{21}&a_{22}&\\cdots&a_{2n}&\\vert& b_2\\nonumber\\\\\n",
    "\\vdots&\\vdots&\\ddots&\\vdots&\\vert &\\vdots\\nonumber\\\\\n",
    "a_{n1}&a_{n2}&\\cdots&a_{nn}&\\vert& b_n\\nonumber\\\\\n",
    "\\end{array}\\right)$$\n",
    "\n",
    "- Elementary operations on the augmented matrix:\n",
    "\n",
    "    1. Multiply a row by a (non-zero) scalar.\n",
    "    2. Add to one row a multiple of another.\n",
    "    3. Interchange the positions of two rows.\n",
    "    \n",
    "    \n",
    "- The Gaussian method combines operations 1 and 2 to transform:\n",
    "\n",
    "    $$\\left(A\\vert B\\right)=\\left(\n",
    "    \\begin{array}{ccccccc}\n",
    "    a_{11}&a_{12}&a_{31}&\\cdots&a_{1n}&\\vert& b_1\\nonumber\\\\\n",
    "    a_{21}&a_{22}&a_{32}&\\cdots&a_{2n}&\\vert& b_2\\nonumber\\\\\n",
    "    a_{31}&a_{32}&a_{33}&\\cdots&a_{3n}&\\vert& b_3\\nonumber\\\\\n",
    "    \\vdots&\\vdots&\\vdots&\\ddots&\\vdots&\\vert &\\vdots\\nonumber\\\\\n",
    "    a_{n1}&a_{n2}&a_{n3}&\\cdots&a_{nn}&\\vert& b_n\\nonumber\\\\\n",
    "    \\end{array}\\right)\\quad\\Rightarrow\\quad \n",
    "    \\left(\n",
    "    \\begin{array}{ccccccc}\n",
    "     1 &\\bar a_{12}&\\bar a_{31}&\\cdots&\\bar a_{1n}&\\vert&\\bar b_1\\nonumber\\\\\n",
    "    0& 1&\\bar a_{32}&\\cdots&\\bar a_{2n}&\\vert&\\bar b_2\\nonumber\\\\\n",
    "    0&0& 1 &\\cdots&\\bar a_{3n}&\\vert&\\bar b_3\\nonumber\\\\\n",
    "    \\vdots&\\vdots&\\vdots&\\ddots&\\vdots&\\vert &\\vdots\\nonumber\\\\\n",
    "    0&0&0&\\cdots& 1 &\\vert&\\bar b_n\\nonumber\\\\\n",
    "    \\end{array}\\right)$$\n",
    "\n",
    "    where the second system of equations can be solved by back substitution.\n",
    "\n",
    "**How can we obtain the triangular matrix?** \n",
    "\n",
    "- We divide the **first** row by the **first** element $a_{11}$.\n",
    "- We subtract from row $j>1$ the first row multiplied by its first element $a_{j1}$.\n",
    "- We divide the **second** row by its **second** element $a_{22}$.\n",
    "- We subtract from row $j>2$ the second row multiplied by its first element $a_{j2}$.\n",
    "- We continue in the same way until reaching the last element.\n",
    "\n",
    "**How is back substitution performed?** \n",
    "- The value of $x_n=\\bar b_n$.\n",
    "- The value of $x_{n-1}=\\bar b_{n-1} -\\bar a_{n-1,n} x_n$.\n",
    "- We continue subtracting from the previous rows the value of all the unknowns we have just solved, multiplied by their corresponding coefficient in the row.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "983add83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.],\n",
       "       [-1.],\n",
       "       [-2.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eligauss(A,B):\n",
    "    \"\"\"Gaussian Elimination for AX = B.\n",
    "\n",
    "    Args:\n",
    "        A (np.array): Main Matrix of the system\n",
    "        B (np.array): Independent Matrix of the system\n",
    "\n",
    "    Returns:\n",
    "        np.array: X (value of n variables in the system of equations)\n",
    "    \"\"\"\n",
    "\n",
    "    M = np.column_stack((A, B))\n",
    "    N = len(B)\n",
    "    \n",
    "    for i in range(N):\n",
    "        M[i, :] /= M[i, i]\n",
    "        for j in range(i+1, N):\n",
    "            M[j] -= M[j, i]*M[i, :]\n",
    "            \n",
    "    x = np.zeros([N, 1], float)\n",
    "    for k in range(N-1, -1, -1):\n",
    "        x[k] = M[k, N]\n",
    "        for s in range(k+1, N):\n",
    "            x[k] -= M[k, s]*x[s]\n",
    "    return np.array(x)\n",
    "\n",
    "A = np.array([[2, 1, 4, 1], [3, 4, -1, -1], [1, -4, 1, 5], [2, -2, 1, 3]], float)\n",
    "B = np.array([[-4], [3], [9], [7]], float)\n",
    "eligauss(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56da6a7a",
   "metadata": {},
   "source": [
    "## Pivot Method.\n",
    "\n",
    "- Gaussian elimination requires dividing at each step by the element $a_{ii}$, which is only possible if this element is nonzero.\n",
    "\n",
    "- The pivot method combines Gaussian elimination with elementary matrix operation 3:  \n",
    "  the interchange of one row with another.\n",
    "\n",
    "- This guarantees that at no step will a diagonal element be equal to 0.\n",
    "\n",
    "- There is no unique way to do this.\n",
    "\n",
    "- The general rule is to interchange, at each step, row $m$ with a row $j>m$ such that $\\vert a_{jm}\\vert$ has the maximum value among all $a_{km}$ with $m\\le k\\le n$.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb988491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.  3.  9.  7.]\n"
     ]
    }
   ],
   "source": [
    "def eligausspiv(A,B):\n",
    "    \"\"\"Pivoting Gaussian Elimination for AX = B.\n",
    "\n",
    "    Args:\n",
    "        A (np.array): Main Matrix of the system\n",
    "        B (np.array): Independent Matrix of the system\n",
    "\n",
    "    Returns:\n",
    "        np.array: X (value of n variables in the system of equations)\n",
    "    \"\"\"\n",
    "    M = np.column_stack((A, B))\n",
    "    N = len(B)\n",
    "    \n",
    "    for m in range(N):\n",
    "        piv = m\n",
    "        large = abs(M[m, m])\n",
    "        for i in range(m+1, N):\n",
    "            if abs(M[i, m]) > large:\n",
    "                largest = M[i, m]\n",
    "                piv = i\n",
    "        for i in range(N+1):\n",
    "            M[m, i], M[piv, i] = M[piv, i], M[m, i]\n",
    "            \n",
    "        M[m, :] /= M[m, m]\n",
    "        \n",
    "        for i in range(m+1,N):\n",
    "            M[i, :] -= M[i, m]*M[m, :]\n",
    "            \n",
    "    x = np.zeros(N, float)\n",
    "    for m in range(N-1, -1, -1):\n",
    "        x[m] = M[m, N]\n",
    "        for i in range(m+1, N):\n",
    "            x[m] -= M[m, i]*x[i]\n",
    "    return np.array(x)\n",
    "\n",
    "import numpy as np\n",
    "A = np.array([[0., 1., 4., 1.], [3., 4., -1., -1.], [1., -4., 1., 5.], [2., -2., 1., 3.]])\n",
    "B = np.array([[-4.], [3.], [9.], [7.]])\n",
    "x = eligausspiv(A, B)\n",
    "print(np.dot(A, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf729a81",
   "metadata": {},
   "source": [
    "## LU Factorization.\n",
    "\n",
    "- For a matrix with $n$ rows, we need to define $n$ matrices $L_i$ with $i=1,\\cdots,n$.\n",
    "\n",
    "- Once these have been obtained, the problem consists of applying them to the augmented matrix and performing back substitution:\n",
    "\n",
    "    $$L_n\\cdots L_2\\cdot L_1\\cdot A=L_n\\cdots L_2\\cdot L_1\\cdot V,$$\n",
    "\n",
    "- Since the product $L_n\\cdots L_2\\cdot L_1\\cdot A$ is always the same, it does not need to be recomputed if the value of $V$ changes. \n",
    "  \n",
    "  \n",
    "- In practice, however, one attempts to minimize the operations performed on $V$,  \n",
    "  so that its values are used only for back substitution. \n",
    "  \n",
    "  \n",
    "- This is achieved by defining the matrices:\n",
    "\n",
    "    $$L=L_1^{-1}L_2^{-1}\\cdots L_n^{-1}\\quad\\text{and}\\quad U=L_n\\cdots L_2\\cdot L_1\\cdot A,$$\n",
    "\n",
    "    which satisfy:\n",
    "\n",
    "    $$L\\cdot U =A,\\quad\\Rightarrow\\quad L\\cdot U\\cdot X =V$$\n",
    "\n",
    "- $U$, as we have seen, is an upper triangular matrix.  \n",
    "\n",
    "- In principle, computing $L$ requires calculating the inverse of each of the elementary matrices and operating with them.\n",
    "\n",
    "* But this is not necessary:  \n",
    "<br>\n",
    "\n",
    "    - the matrix $L$ is the lower triangular matrix whose columns are generated at each step when transforming the matrix $A$ into an upper triangular matrix, that is, when computing $U$. \n",
    "\n",
    "\n",
    "* The matrix $L$ is a lower triangular matrix, whereas the matrix $U$ is an upper triangular matrix.\n",
    "\n",
    "\n",
    "* Therefore, each of them can be solved by substitution: backward substitution for $U$ and forward substitution for $L$.\n",
    "\n",
    "\n",
    "* Specifically, we want to solve:\n",
    "\n",
    "    $$L\\cdot U\\cdot X = V,$$\n",
    "\n",
    "    which can be decomposed into:\n",
    "\n",
    "    $$U\\cdot X = Y$$\n",
    "\n",
    "    and the problem:\n",
    "\n",
    "    $$L\\cdot Y =V.$$\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19d9acdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2. -1. -2.  1.]\n",
      "[-4.  3.  9.  7.]\n"
     ]
    }
   ],
   "source": [
    "def LU(A,V):\n",
    "    \"\"\"LU Factorization for AX = V (A = LU) system of equations.\n",
    "\n",
    "    Args:\n",
    "        A (np.array): Main system matrix\n",
    "        V (np.array): Independent system matrix\n",
    "    Returns:\n",
    "        np.array: system solution\n",
    "    \"\"\"\n",
    "    \n",
    "    def factLU(A):\n",
    "        N = len(A)\n",
    "        L = np.zeros([N, N], float)\n",
    "        U = np.copy(A)\n",
    "        for m in range(N):\n",
    "            L[m:N, m] = U[m:N, m]\n",
    "            div = U[m, m]\n",
    "            U[m, :] /= div\n",
    "            for i in range(m + 1, N):\n",
    "                mult = U[i, m]\n",
    "                U[i, :] -= mult*U[m, :]\n",
    "        return L, U\n",
    "    \n",
    "    L, U = factLU(A)\n",
    "    N = len(V)\n",
    "    y = np.empty(N, float)\n",
    "    for m in range(N):\n",
    "        y[m] = V[m]\n",
    "        for i in range(m):\n",
    "            y[m] -= L[m, i]*y[i]\n",
    "        y[m] /= L[m, m]\n",
    "    \n",
    "    x = np.empty(N, float)\n",
    "    for m in range(N-1, -1, -1):\n",
    "        x[m] = y[m]\n",
    "        for i in range(m+1, N):\n",
    "            x[m] -= U[m, i]*x[i]\n",
    "    return(x)\n",
    "\n",
    "\n",
    "\n",
    "A = np.array([[2, 1, 4, 1], [3, 4, -1, -1], [1, -4, 1, 5], [2, -2, 1, 3]], float)\n",
    "B = np.array([[-4], [3], [9], [7]], float)\n",
    "x = LU(A, B)\n",
    "print(x)\n",
    "print(np.dot(A, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8595d422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of operations: 42\n",
      "[ 1.61904762 -0.42857143 -1.23809524  1.38095238]\n"
     ]
    }
   ],
   "source": [
    "def LUpiv(A, V):\n",
    "    \"\"\"Pivoting LU Factorization for AX = V (A = LU) system of equations.\n",
    "\n",
    "    Args:\n",
    "        A (np.array): Main system matrix\n",
    "        V (np.array): Independent system matrix\n",
    "    Returns:\n",
    "        np.array: system solution\n",
    "    \"\"\"\n",
    "\n",
    "    def factLUpiv(A):\n",
    "        N = len(A)\n",
    "        L = np.zeros([N, N], float)\n",
    "        U = np.copy(A)\n",
    "        P = np.empty(N, int)\n",
    "\n",
    "        for m in range(N):\n",
    "            L[m:N, m] = U[m:N, m]\n",
    "\n",
    "            pivot = m\n",
    "            largest = abs(U[m, m])\n",
    "            for i in range(m + 1, N):\n",
    "                if abs(U[i, m]) > largest:\n",
    "                    largest = abs(U[i, m])\n",
    "                    pivot = i\n",
    "\n",
    "            for i in range(N):\n",
    "                U[m, i], U[pivot, i] = U[pivot, i], U[m, i]\n",
    "                L[m, i], L[pivot, i] = L[pivot, i], L[m, i]\n",
    "\n",
    "            P[m] = pivot\n",
    "\n",
    "            div = U[m, m]\n",
    "            U[m, :] /= div\n",
    "\n",
    "            for i in range(m + 1, N):\n",
    "                mult = U[i, m]\n",
    "                U[i, :] -= mult * U[m, :]\n",
    "\n",
    "        return L, U, P\n",
    "\n",
    "    L, U, P = factLUpiv(A)\n",
    "    N = len(V)\n",
    "\n",
    "    for m in range(N):\n",
    "        pivot = P[m]\n",
    "        V[m], V[pivot] = V[pivot], V[m]\n",
    "\n",
    "    y = np.empty(N, float)\n",
    "    for m in range(N):\n",
    "        y[m] = V[m]\n",
    "        for i in range(m):\n",
    "            y[m] -= L[m, i] * y[i]\n",
    "        y[m] /= L[m, m]\n",
    "\n",
    "    x = np.empty(N, float)\n",
    "    for m in range(N - 1, -1, -1):\n",
    "        x[m] = y[m]\n",
    "        for i in range(m + 1, N):\n",
    "            x[m] -= U[m, i] * x[i]\n",
    "\n",
    "    n = int((2 * N**3) / 3)\n",
    "    print(\"Number of operations:\", n)\n",
    "\n",
    "    return x\n",
    "\n",
    "A = np.array([[0, 1, 4, 1],\n",
    "              [3, 4, -1, -1],\n",
    "              [1, -4, 1, 5],\n",
    "              [2, -2, 1, 3]], float)\n",
    "\n",
    "V = np.array([-4, 3, 9, 7], float)\n",
    "\n",
    "x = LUpiv(A, V)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b5999f",
   "metadata": {},
   "source": [
    "## Matrix Inverse\n",
    "\n",
    "- The inverse matrix is calculated as:  \n",
    "\n",
    "    $$A^{-1} = \\frac{1}{\\det(A)} \\left[C\\right]^T$$\n",
    "\n",
    "    where $C_{ij}$ is the cofactor of $A_{ij}$.\n",
    "\n",
    "- However, its direct application is computationally expensive.\n",
    "\n",
    "- Moreover, it entails rounding errors that can be non-negligible.\n",
    "\n",
    "- In cases where it is necessary to compute it, the procedure is to solve the system:\n",
    "\n",
    "    $$A \\cdot A^{-1} = I$$\n",
    "\n",
    "    by applying Gaussian elimination or LU decomposition to each of the columns of $A^{-1}$ and $I$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3594f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse(A):\n",
    "    m, n = np.shape(A)\n",
    "    invA = np.zeros([m, n])\n",
    "    for i in range(m):\n",
    "        I = np.zeros([m, 1], float)\n",
    "        I[i] = 1\n",
    "        invA[:, i] += eligauss(A, I)[:, 0]\n",
    "    return invA\n",
    "\n",
    "\n",
    "A = np.array([[2, 1, 4, 1],\n",
    "              [3, 4, -1, -1],\n",
    "              [1, -4, 1, 5],\n",
    "              [2, -2, 1, 3]], float)\n",
    "\n",
    "iA = inverse(A)\n",
    "\n",
    "I = np.dot(A, iA)\n",
    "print(I)\n",
    "print()\n",
    "print(I[2, 2])\n",
    "print()\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        I[i, j] = round(I[i, j], 0)\n",
    "\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e395a8",
   "metadata": {},
   "source": [
    "## Tridiagonal and Band Matrices\n",
    "\n",
    "- In physics, it is very common to encounter systems of equations:\n",
    "\n",
    "    $$A \\cdot X = B,$$\n",
    "\n",
    "    with $A$ being a tridiagonal matrix, that is:\n",
    "\n",
    "    $$A = \\left(\n",
    "    \\begin{array}{llllll}\n",
    "    a_{11} & a_{12} &      &           &          &          \\nonumber\\\\\n",
    "    a_{21} & a_{22} & a_{23} &           &          &          \\nonumber\\\\\n",
    "          & a_{32} & a_{33} & a_{34}     &          &          \\nonumber\\\\\n",
    "          &        & \\ddots & \\ddots     & \\!\\!\\!\\ddots    &          \\nonumber\\\\\n",
    "          &        &        & a_{n-2n-1} & a_{n-1n-1} & a_{n-1n} \\nonumber\\\\\n",
    "          &        &        &           & a_{nn-1}  & a_{nn} \\nonumber\\\\\n",
    "    \\end{array}\\right)$$\n",
    "\n",
    "    where all elements not shown are zero.\n",
    "\n",
    "- For example, in the algorithm for defining cubic splines or, in general, in all those systems where only nearest-neighbor interactions exist.\n",
    "\n",
    "- Tridiagonal problems are ideal for applying Gaussian elimination, and their algorithm can be simplified compared to the general case.\n",
    "\n",
    "- The idea is that for a given step of Gaussian elimination (for a given row),  \n",
    "  it is not necessary to traverse all other rows, only the next one.\n",
    "\n",
    "- Similarly, in back substitution, the equation for the variable $x_n$ will only involve $x_{n+1}$.\n",
    "\n",
    "- Band matrices are those in which:\n",
    "\n",
    "$$a_{ij} = 0 \\quad \\text{if} \\quad j < i - k_1 \\quad || \\quad j > i + k_2 \\quad \\text{with} \\quad k_1, k_2 > 0.$$\n",
    "\n",
    "- The algorithm to solve them will be the same as for tridiagonal matrices, but traversing in each step the next $k_1$ rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bfeaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eligauss_tri(A, v):\n",
    "    \"\"\"Gauss Elimination for band matrix A.\n",
    "\n",
    "    Args:\n",
    "        A (np.array): Main Matrix of the system\n",
    "        B (np.array): Independent Matrix of the system\n",
    "\n",
    "    Returns:\n",
    "        np.array: X (value of n variables in the system of equations)\n",
    "    \"\"\"\n",
    "    N = len(v)\n",
    "\n",
    "    for i in range(N - 1):\n",
    "        A[i, i + 1] /= A[i, i]\n",
    "        v[i] /= A[i, i]\n",
    "\n",
    "        A[i + 1, i + 1] -= A[i + 1, i] * A[i, i + 1]\n",
    "        v[i + 1] -= A[i + 1, i] * v[i]\n",
    "\n",
    "    v[N - 1] /= A[N - 1, N - 1]\n",
    "\n",
    "    x = np.zeros(N, float)\n",
    "    x[N - 1] = v[N - 1]\n",
    "\n",
    "    for i in range(N - 2, -1, -1):\n",
    "        x[i] = v[i] - A[i, i + 1] * x[i + 1]\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd93ab2b",
   "metadata": {},
   "source": [
    "## Jacobi Method\n",
    "\n",
    "- The Jacobi method is based on decomposing a matrix whose diagonal elements are nonzero (pivoting must be applied if not the case) into:\n",
    "\n",
    "    $$A = D + L + U$$\n",
    "\n",
    "    where $D$ is diagonal and $L/U$ has nonzero elements only below/above the diagonal.\n",
    "\n",
    "- Therefore, the system of equations $A \\cdot x = v$ can be written as\n",
    "\n",
    "    $$A \\cdot x = (D + L + U) \\cdot x = v \\quad \\Rightarrow \\quad D \\cdot x = v - (L + U) \\cdot x,$$\n",
    "\n",
    "- Since $D$ has nonzero determinant, it is invertible and therefore:\n",
    "\n",
    "    $$x = D^{-1} \\left(v - (L + U) \\cdot x\\right) \\quad \\Rightarrow \\quad x_i = \\frac{1}{a_{ii}} \\left(v_i - \\sum_{j \\neq i} {a_{ij} \\, x_j}\\right), \\quad \\text{with} \\quad i = 1 \\cdots N.$$\n",
    "\n",
    "- Instead of seeking the exact solution, the equation allows for the development of an iterative method.\n",
    "\n",
    "- Defining a starting point $x^{(0)}$, for example $x^{(0)} = 0$ if no other information is available, we obtain for the $k$-th estimate:\n",
    "\n",
    "    $$x_i^{k+1} = \\frac{1}{a_{ii}} \\left(v_i - \\sum_{j \\neq i} {a_{ij} \\, x_j^k}\\right),$$\n",
    "\n",
    "- However, the system will only converge if the condition is satisfied:\n",
    "\n",
    "    $$\\left\\vert D^{-1} \\cdot (L + U) \\right\\vert < 1 \\quad \\Rightarrow \\quad a_{ii} > \\sum_{j \\neq i} \\vert a_{ij} \\vert.$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63622c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi(A, v, eps):\n",
    "    \"\"\"Jacobi's method for solving AX = v.\n",
    "\n",
    "    Args:\n",
    "        A (np.array): main system matrix\n",
    "        v (np.array): independent system matrix\n",
    "        eps (float): desired accuracy\n",
    "\n",
    "    Returns:\n",
    "        np.array: system solution\n",
    "    \"\"\"\n",
    "    N = len(v)\n",
    "\n",
    "    D = np.diag(A)\n",
    "    LU = A - np.diagflat(D)\n",
    "\n",
    "    x0 = np.zeros(N, float)\n",
    "    err = 1e6\n",
    "    it = 0\n",
    "    while err > eps:\n",
    "        x = (v - np.dot(LU, x0)) / D\n",
    "        err = abs(max(x - x0))\n",
    "        x0 = np.copy(x)\n",
    "        it += 1\n",
    "    print(\"Jacobi's method iterations:\", it)\n",
    "    return x\n",
    "\n",
    "A = np.array([[8, 1, 2, 1],\n",
    "              [1, 5, -1, -1],\n",
    "              [1, -4, 6, 1],\n",
    "              [1, -2, 1, 5]], float)\n",
    "\n",
    "V = np.array([-1, 3, 2, 1], float)\n",
    "\n",
    "x1 = jacobi(A, V, 1e-6)\n",
    "print(x1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4921cc42",
   "metadata": {},
   "source": [
    "## Gauss-Seidel Method\n",
    "\n",
    "- This corresponds to a variation of the Jacobi method, based on the observation that the matrix $D + L$ is lower triangular and can therefore be solved by forward substitution:\n",
    "\n",
    "    $$(L + D) \\cdot x = v - U \\cdot x,$$\n",
    "\n",
    "- Therefore, starting from an initial estimate for $x$, we can solve the system exactly, which allows us to accelerate the convergence of the Jacobi method.\n",
    "\n",
    "    $$x_i^{k+1} = \\frac{1}{a_{ii}} \\left(v_i - \\sum_{j=1}^{i-1} {a_{ij} \\, x_j^{k+1}} - \\sum_{j=i+1}^{N} {a_{ij} \\, x_j^k} \\right),$$\n",
    "\n",
    "    which converges if\n",
    "\n",
    "    $$\\left\\vert (D + L)^{-1} \\cdot U \\right\\vert < 1,$$\n",
    "\n",
    "    conditions that are satisfied if $A$ is positive definite or diagonally dominant.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_seidel(A, v, eps):\n",
    "    \"\"\"Gauss-Seidel's method for solving AX = v.\n",
    "\n",
    "    Args:\n",
    "        A (np.array): main system matrix\n",
    "        v (np.array): independent system matrix\n",
    "        eps (float): desired accuracy\n",
    "\n",
    "    Returns:\n",
    "        np.array: system solution\n",
    "    \"\"\"\n",
    "    N = len(v)\n",
    "\n",
    "    DL = np.tril(A)\n",
    "    U = A - DL\n",
    "    x0 = np.zeros(N, float)\n",
    "    err = 1e6\n",
    "    it = 0\n",
    "    while err > eps:\n",
    "        x = (v - np.dot(U, x0))\n",
    "        for m in range(N):\n",
    "            for i in range(m):\n",
    "                x[m] -= DL[m, i] * x[i]\n",
    "            x[m] /= DL[m, m]\n",
    "        err = abs(max(x - x0))\n",
    "        x0 = np.copy(x)\n",
    "        it += 1\n",
    "    print(\"Gauss-Seidel's method iterations:\", it)\n",
    "    return x\n",
    "\n",
    "\n",
    "A = np.array([[8, 1, 2, 1],\n",
    "              [1, 5, -1, -1],\n",
    "              [1, -4, 6, 1],\n",
    "              [1, -2, 1, 5]], float)\n",
    "\n",
    "V = np.array([-1, 3, 2, 1], float)\n",
    "\n",
    "x1 = gauss_seidel(A, V, 1e-6)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd8fec6",
   "metadata": {},
   "source": [
    "## Successive Over-Relaxation (SOR) Method\n",
    "\n",
    "- The Gauss-Seidel method can be written as:\n",
    "\n",
    "    $$x_i^{k+1} = x_i^k + \\frac{1}{a_{ii}} \\left(v_i - \\sum_{j=1}^{i-1} {a_{ij} \\, x_j^{k+1}} - \\sum_{j=i}^{N} {a_{ij} \\, x_j^k} \\right),$$\n",
    "\n",
    "    where we have simply added and subtracted the estimate $x^k$ in the solution.\n",
    "\n",
    "- Relaxation methods use that the combination $D + \\omega L$, with $\\omega$ being an arbitrary parameter, is a lower triangular matrix to generalize the Gauss-Seidel method for the case $\\omega \\neq 0$:\n",
    "\n",
    "    $$x_i^{k+1} = (1 - \\omega) \\, x_i^k + \\frac{\\omega}{a_{ii}} \\left(v_i - \\sum_{j=1}^{i-1} {a_{ij} \\, x_j^{k+1}} - \\sum_{j=i+1}^{N} {a_{ij} \\, x_j^k} \\right),$$\n",
    "\n",
    "    which allows finding the value of $\\omega$ that optimizes convergence.\n",
    "\n",
    "- Moreover, for values $0 < \\omega < 2$, the successive over-relaxation method converges for any symmetric positive definite matrix.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10268885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOR method iterations: 9\n",
      "(array([-0.57409704,  1.02366121,  1.02490661,  0.51930259]), 9)\n"
     ]
    }
   ],
   "source": [
    "def relax(A, v, w, eps):\n",
    "    N = len(v)\n",
    "    DL = np.tril(A)\n",
    "    U = A - DL\n",
    "    x0 = np.zeros(N, float)\n",
    "\n",
    "    err = 1e6\n",
    "    it = 0\n",
    "\n",
    "    while err > eps:\n",
    "        x = (v - np.dot(U, x0))\n",
    "        for m in range(N):\n",
    "            for i in range(m):\n",
    "                x[m] -= DL[m, i] * x[i]\n",
    "            x[m] = (1 - w) * x0[m] + w / DL[m, m] * x[m]\n",
    "        err = abs(max(x - x0))\n",
    "        x0 = np.copy(x)\n",
    "        it += 1\n",
    "    print(\"SOR method iterations:\", it)\n",
    "    return x, it\n",
    "\n",
    "\n",
    "A = np.array([[8, 1, 2, 1],\n",
    "              [1, 5, -1, -1],\n",
    "              [1, -4, 6, 1],\n",
    "              [1, -2, 1, 5]], float)\n",
    "\n",
    "V = np.array([-1, 3, 2, 1], float)\n",
    "\n",
    "x1 = relax(A, V, 1.1, 1e-6)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d0b645",
   "metadata": {},
   "source": [
    "## QR Decomposition\n",
    "\n",
    "- The most common method used to compute the eigenvalues of a matrix is the QR decomposition.\n",
    "\n",
    "- It is similar to the $LU$ factorization, but in this case the matrix $A$ is decomposed as\n",
    "\n",
    "    $$A = Q \\cdot R,$$\n",
    "\n",
    "    where $Q$ is an orthogonal matrix and $R$ is an upper triangular matrix.\n",
    "\n",
    "- The QR factorization corresponds to applying the Gram-Schmidt method to obtain an orthonormal basis.\n",
    "\n",
    "- To do this, consider the matrix $A$ as a set of $N$ column vectors $a_1, \\cdots, a_N$\n",
    "\n",
    "    $$A = \\left(\n",
    "    \\begin{array}{cccc}\n",
    "    \\vert & \\vert & \\cdots & \\vert \\nonumber\\\\\n",
    "    a_1 & a_2 & \\cdots & a_n \\nonumber\\\\\n",
    "    \\vert & \\vert & \\cdots & \\vert \\nonumber\\\\\n",
    "    \\end{array}\\right)$$\n",
    "\n",
    "    which we can use to construct the vectors $u_i$ and $q_i$ for $i = 1, \\cdots, N$ defined by\n",
    "\n",
    "    \\begin{align}\n",
    "    u_1 =&\\, a_1, \\quad &q_1 = \\frac{u_1}{\\vert u_1 \\vert}, \\nonumber\\\\\n",
    "    u_2 =&\\, a_2 - \\left(q_1 \\cdot a_2\\right) \\, q_1, \\quad &q_2 = \\frac{u_2}{\\vert u_2 \\vert}, \\nonumber\\\\\n",
    "    u_3 =&\\, a_3 - \\left(q_1 \\cdot a_3\\right) q_1 - \\left(q_2 \\cdot a_3\\right) q_2, \\quad &q_3 = \\frac{u_3}{\\vert u_3 \\vert}, \\nonumber\\\\\n",
    "    \\end{align}\n",
    "\n",
    "    and in general\n",
    "\n",
    "    $$u_i = a_i - \\sum_{j=1}^{i-1} \\left(a_j \\cdot q_j \\right) q_j, \\quad q_i = \\frac{u_i}{\\vert u_i \\vert},$$\n",
    "\n",
    "- The vectors $q_i$ form a basis of orthonormal vectors, which allows writing:\n",
    "\n",
    "    $$A = \\left(\n",
    "    \\begin{array}{cccc}\n",
    "    \\vert & \\vert & \\cdots & \\vert \\nonumber\\\\\n",
    "    a_1 & a_2 & \\cdots & a_n \\nonumber\\\\\n",
    "    \\vert & \\vert & \\cdots & \\vert \\nonumber\\\\\n",
    "    \\end{array}\\right)\n",
    "    = \\left(\n",
    "    \\begin{array}{cccc}\n",
    "    \\vert & \\vert & \\cdots & \\vert \\nonumber\\\\\n",
    "    q_1 & q_2 & \\cdots & q_n \\nonumber\\\\\n",
    "    \\vert & \\vert & \\cdots & \\vert \\nonumber\\\\\n",
    "    \\end{array}\\right)\n",
    "    \\cdot\n",
    "    \\left(\n",
    "    \\begin{array}{cccc}\n",
    "    \\vert u_1 \\vert & \\left(q_1 \\cdot a_2\\right) & \\cdots & \\left(q_1 \\cdot a_n\\right) \\nonumber\\\\\n",
    "    0 & \\vert u_2 \\vert & \\cdots & \\left(q_2 \\cdot a_n\\right) \\nonumber\\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\nonumber\\\\\n",
    "    \\end{array}\\right)\n",
    "    = Q \\cdot R$$\n",
    "\n",
    "---\n",
    "\n",
    "### Successive QR Decompositions\n",
    "\n",
    "- Once we have factorized our matrix $A$ into an orthogonal matrix $Q_1$ and an upper triangular matrix $R_1$\n",
    "\n",
    "    $$A = Q_1 \\cdot R_1,$$\n",
    "\n",
    "    multiplying $Q_1$ on the right and $Q_1^T$ on the left gives\n",
    "\n",
    "    $$Q_1^T \\cdot A \\cdot Q_1 = Q_1^T \\cdot Q_1 \\cdot R_1 \\cdot Q_1 = R_1 \\cdot Q_1,$$\n",
    "\n",
    "    using the fact that $Q_1$ is orthogonal.\n",
    "\n",
    "- Calling $A_1 = Q_1^T \\cdot A \\cdot Q_1$, it is important to note that $A$ and $A_1$ have the same eigenvalues (same spectrum) and are therefore similar matrices.\n",
    "\n",
    "- Calling $v_1$ and $\\lambda_1$ one of the eigenvectors and eigenvalues of $A_1$, we have\n",
    "\n",
    "    $$A_1 \\cdot v_1 = Q_1^T \\cdot A \\cdot Q_1 \\cdot v_1 = \\lambda_1 \\, v_1 \\Rightarrow A \\cdot (Q_1 \\cdot v_1) = \\lambda_1 (Q_1 \\cdot v_1),$$\n",
    "\n",
    "    and therefore $\\lambda_1$ is also an eigenvalue of $A$ with eigenvector $Q_1 \\cdot v_1$.\n",
    "\n",
    "- This implies that the eigenvalue problem remains the same, and we can focus on the new matrix $A_1$, which can be further decomposed as\n",
    "\n",
    "    $$A_1 = Q_1^T \\cdot A \\cdot Q_1 = Q_2 \\cdot R_2,$$\n",
    "\n",
    "    and multiplying again by $Q_2$ and $Q_2^T$ on the right and left, we obtain a new matrix $A_2$\n",
    "\n",
    "    $$A_2 = Q_2^T \\cdot A_1 \\cdot Q_2 = Q_2^T \\cdot Q_1^T \\cdot A \\cdot Q_1 \\cdot Q_2 = R_2 \\cdot Q_2.$$\n",
    "\n",
    "- We can repeat this process $n$ times, obtaining at each iteration:\n",
    "\n",
    "    \\begin{align}\n",
    "    A_1 =&\\, Q_1^T \\cdot A \\cdot Q_1, \\nonumber\\\\\n",
    "    A_2 =&\\, Q_2^T \\cdot Q_1^T \\cdot A \\cdot Q_1 \\cdot Q_2, \\nonumber\\\\\n",
    "    A_3 =&\\, Q_3^T \\cdot Q_2^T \\cdot Q_1^T \\cdot A \\cdot Q_1 \\cdot Q_2 \\cdot Q_3, \\nonumber\\\\\n",
    "    \\vdots \\quad & \\quad \\quad \\quad \\quad \\vdots, \\nonumber\\\\\n",
    "    A_n =&\\, (Q_n^T \\cdots Q_1^T) \\cdot A \\cdot (Q_1 \\cdots Q_n), \\nonumber\\\\\n",
    "    \\end{align}\n",
    "\n",
    "- An orthogonal matrix is simply a change of coordinates, i.e., a rotation.\n",
    "\n",
    "- For example, in two dimensions, $N = 2$:\n",
    "\n",
    "    $$Q = \\left(\n",
    "    \\begin{array}{cc}\n",
    "    \\cos \\alpha & -\\sin \\alpha \\nonumber\\\\\n",
    "    \\sin \\alpha & \\cos \\alpha \\nonumber\\\\\n",
    "    \\end{array}\\right),$$\n",
    "\n",
    "- Rotating the coordinate system of our matrix $k$ times transforms the matrix into a diagonal matrix.\n",
    "\n",
    "- The proof that in the limit as $k \\to \\infty$ this is the case is complicated, but it can be understood by noting that while off-diagonal elements involve the product of sines and cosines, the diagonal elements always sum squares of sines and cosines.\n",
    "\n",
    "- Therefore, the idea is to continue the process until the matrix $A_k$ becomes diagonal.\n",
    "\n",
    "- The off-diagonal terms become progressively smaller until they are zero or close enough to zero to be neglected.\n",
    "\n",
    "- Thus, given a desired precision, we can diagonalize the matrix through similarity transformations until obtaining a diagonal matrix.\n",
    "\n",
    "- Defining the orthogonal matrix:\n",
    "\n",
    "    $$V = \\left(Q_1 \\cdots Q_n\\right) = \\prod_{i=1}^k Q_i,$$\n",
    "\n",
    "    we obtain:\n",
    "\n",
    "    $$V^T \\cdot A \\cdot V = D \\;\\Rightarrow\\; A \\cdot V = D \\cdot V.$$\n",
    "\n",
    "---\n",
    "\n",
    "Given a precision $\\epsilon$ for the off-diagonal terms:\n",
    "\n",
    "1. Create an $N \\times N$ matrix $V$ to store the eigenvectors. Initialize $V$ as the identity matrix.\n",
    "\n",
    "2. Compute the QR factorization of $A$: $A = Q \\cdot R$.\n",
    "\n",
    "3. Update $A$ to a new value: $A = R \\cdot Q$.\n",
    "\n",
    "4. Multiply $V$ on the right by $Q$.\n",
    "\n",
    "5. Check the off-diagonal terms of the new $A$. If their absolute values are less than $\\epsilon$, the process is complete. Otherwise, return to step 2.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e739f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21.  0.  0.  0.]\n",
      " [ 0. -8.  0.  0.]\n",
      " [ 0.  0. -3.  0.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "\n",
      "[[ 0.43151698 -0.38357064 -0.77459666 -0.25819889]\n",
      " [ 0.38357063  0.43151698 -0.2581989   0.77459667]\n",
      " [ 0.62330228  0.52740965  0.25819889 -0.51639778]\n",
      " [ 0.52740965 -0.62330227  0.51639779  0.25819889]]\n"
     ]
    }
   ],
   "source": [
    "def module(v):\n",
    "    \"\"\"Module of a vector v.\n",
    "\n",
    "    Args:\n",
    "        v (np.array): 1-D array.\n",
    "\n",
    "    Returns:\n",
    "        np.array: module of argument vector\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.dot(v, v))\n",
    "\n",
    "\n",
    "def QR(A, eps):\n",
    "    \"\"\"QR factorization of matrix A with accuracy eps\n",
    "\n",
    "    Args:\n",
    "        A (np.arrayt): matrix to factorize\n",
    "        eps (float): desired accuracy\n",
    "\n",
    "    Returns:\n",
    "        np.array: two matrices corresponding to A's QR factorization\n",
    "    \"\"\"\n",
    "    N = len(A)\n",
    "\n",
    "    def QR_factorization(A):\n",
    "        N = len(A)\n",
    "        U = np.zeros([N, N], float)\n",
    "        Q = np.zeros([N, N], float)\n",
    "        R = np.zeros([N, N], float)\n",
    "\n",
    "        for m in range(N):\n",
    "            U[:, m] = A[:, m]\n",
    "            for i in range(m):\n",
    "                R[i, m] = np.dot(Q[:, i], A[:, m])\n",
    "                U[:, m] -= R[i, m] * Q[:, i]\n",
    "            R[m, m] = module(U[:, m])\n",
    "            Q[:, m] = U[:, m] / R[m, m]\n",
    "        return Q, R\n",
    "\n",
    "    V = np.identity(N, float)\n",
    "    delta = 1.0\n",
    "    while delta > eps:\n",
    "        Q, R = QR_factorization(A)\n",
    "        A = np.dot(R, Q)\n",
    "        V = np.dot(V, Q)\n",
    "        Ac = np.copy(A)\n",
    "        for i in range(N):\n",
    "            Ac[i, i] = 0.0\n",
    "        delta = np.max(np.absolute(Ac))\n",
    "    for i in range(len(Q)):\n",
    "        for j in range(len(Q)):\n",
    "            A[i, j] = int(round(A[i, j]))\n",
    "    return A, V\n",
    "\n",
    "\n",
    "A = np.array([[1, 4, 8, 4],\n",
    "              [4, 2, 3, 7],\n",
    "              [8, 3, 6, 9],\n",
    "              [4, 7, 9, 2]], float)\n",
    "\n",
    "D, V = QR(A, 1e-6)\n",
    "print(D)\n",
    "print()\n",
    "print(V)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
